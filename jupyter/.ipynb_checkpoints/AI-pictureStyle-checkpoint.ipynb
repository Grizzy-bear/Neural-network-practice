{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from keras.models import Sequential\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "#cImage = './data/303.jpg'\n",
    "cImPath = 'F:\\\\1AFILE\\\\python\\\\Neural-network-practice\\\\jupyter\\data\\\\JobsNuorena.png'\n",
    "# sImage = \"./data/JobsNuorena.jpg\"\n",
    "sImPath = \"F:\\\\1AFILE\\\\python\\\\Neural-network-practice\\\\jupyter\\\\data\\\\303.png\"\n",
    "genImOutputPath = \"F:\\\\1AFILE\\\\python\\\\Neural-network-practice\\\\jupyter\\\\data\\\\3.png\"\n",
    "\n",
    "# cImageObj = Image.open(cImage)\n",
    "# print(cImage.format)\n",
    "# print(img_to_array(sImPath))\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "targetHeight=512\n",
    "targetWidth = 512\n",
    "targetSize = (targetHeight, targetWidth)\n",
    "\n",
    "cImageOrig = Image.open(cImPath)\n",
    "cImageSizeOrig = cImageOrig.size\n",
    "cImage = load_img(path=cImPath, target_size=targetSize)\n",
    "cImArr = img_to_array(cImage)\n",
    "cImArr = K.variable(preprocess_input(np.expand_dims(cImArr, axis=0)), dtype='float32')\n",
    "\n",
    "sImage = load_img(path=sImPath, target_size=targetSize)\n",
    "sImArr = img_to_array(sImage)\n",
    "sImArr = K.variable(preprocess_input(np.expand_dims(sImArr, axis=0)), dtype='float32')\n",
    "\n",
    "gIm0 = np.random.randint(256, size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "gIm0 = preprocess_input(np.expand_dims(gIm0, axis=0))\n",
    "\n",
    "gImPlaceholder = K.placeholder(shape=(1, targetWidth, targetHeight, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define loss and helper function\n",
    "\n",
    "def get_feature_repos(x, layer_names, model):\n",
    "    featMatrics=[]\n",
    "    for ln in layer_names:\n",
    "        selectedLayer = model.get_layer(ln)\n",
    "        featRaw = selectedLayer.output\n",
    "#         featRawShape = K.reshape(featRaw,(M_1, N_1))\n",
    "        featRawShape = K.shape(featRaw).eval(session=tf_session)\n",
    "        N_a = featRawShape[-1]\n",
    "        M_a = featRawShape[1]*featRawShape[2]\n",
    "        featMatrix = K.reshape(featRaw, (M_a, N_a))\n",
    "        featMatrix = K.transpose(featMatrix)\n",
    "        featMatrics.append(featMatrix)\n",
    "    return featMatrics\n",
    "\n",
    "def get_content_loss(F,P):\n",
    "    cLoss = 0.5*K.sum(K.square(F -P))\n",
    "    return cLoss\n",
    "\n",
    "def get_Gram_matrix(F):\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G\n",
    "\n",
    "def get_style_loss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_a = K.int_shape(G)[1]\n",
    "        N_a = K.int_shape(G)[0]\n",
    "#         print(M_l, N_l)\n",
    "        G_gram = get_Gram_matrix(G)\n",
    "        A_gram = get_Gram_matrix(A)\n",
    "#         print(M_1,N_l)\n",
    "        sLoss += w*0.25*K.sum(K.square(G_gram - A_gram))/ (N_a**2*M_a**2)\n",
    "    return sLoss\n",
    "\n",
    "def get_total_loss(gImPlaceholder, alpha=1.0, beta=10000.0):\n",
    "    F = get_feature_repos(gImPlaceholder, layer_names=[cLayerName], model=gModel)[0]\n",
    "    Gs = get_feature_repos(gImPlaceholder, layer_names=sLayerNames, model=gModel)\n",
    "#     contentloss = get_style_loss(ws, Gs, AS)\n",
    "    contentLoss = get_content_loss(F,P)\n",
    "    styleLoss = get_style_loss(ws, Gs, As)\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    return totalLoss\n",
    "\n",
    "def calculate_loss(gImArr):\n",
    "    \"\"\"\n",
    "    generate Image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    grad_fcn = K.function([gModel.input], K.gradients(get_total_loss(gModel.input), [gModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad\n",
    "\n",
    "def get_grad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    grad_fcn = K.function([gModel.input], K.gradients(get_total_loss(gModel.input), [gModel.input]))\n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad\n",
    "\n",
    "def postprocess_array(x):\n",
    "    #Zero-center\n",
    "    if x.shape != (targetWidth, targetHeight, 3):\n",
    "        x = x.reshape((targetWidth, targetHeight, 3))\n",
    "    x[..., 0] += 103.939\n",
    "    x[..., 1] += 116.779\n",
    "    x[..., 2] += 123.68\n",
    "    \n",
    "    x = x[..., ::-1]\n",
    "    x = np.clip(x, 0, 225)\n",
    "    x = x.astype('uint8')\n",
    "    return x\n",
    "\n",
    "def reprocess_array(x):\n",
    "    x = np.expand_dims(x.astype('float64'), axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def save_original_size(x, target_size=cImageOrig):\n",
    "    xIm = Image.fromarray(x)\n",
    "    xIm = xIm.resize(target_size)\n",
    "    xIm.save(genImOutputPath)\n",
    "    return xIm\n",
    "\n",
    "tf_session = K.get_session()\n",
    "cModel = VGG16(include_top=False, weights='imagenet', input_tensor=cImArr)\n",
    "sModel = VGG16(include_top=False, weights='imagenet', input_tensor=sImArr)\n",
    "gModel = VGG16(include_top=False, weights='imagenet', input_tensor=gImPlaceholder)\n",
    "cLayerName = 'block4_conv2'\n",
    "sLayerNames = [\n",
    "                'block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "]\n",
    "P = get_feature_repos(x=cImaArr, layer_names=[cLayerName], model=cModel)[0]\n",
    "As = get_feature_repos(x=sImArr, layer_names=sLayerNames, model=sModel)\n",
    "ws = np.ones(len(sLayerNames))/float(len(sLayerNames))\n",
    "\n",
    "iterations = 600\n",
    "x_val = gIm0.flatten()\n",
    "start = time.time()\n",
    "\n",
    "xopt, f_val, info = fmin_l_bfgs_b(calculate_loss, x_val, fprime=get_grad,\n",
    "                                 maxiter= iterations, disp=True)\n",
    "\n",
    "xOut = postprocess_array(xopt)\n",
    "xIm = save_original_size(xOut)\n",
    "print(\"image saved\")\n",
    "end = time.time()\n",
    "print('Time Token:{}'.format(end-start))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow3.6",
   "language": "python",
   "name": "python_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
